<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Aaron Berk on Aaron Berk</title>
    <link>http://aaronberk.ca/</link>
    <description>Recent content in Aaron Berk on Aaron Berk</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2018 Aaron Berk</copyright>
    <lastBuildDate>Sun, 23 Apr 2017 23:19:00 +0000</lastBuildDate>
    <atom:link href="/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Resource Links</title>
      <link>http://aaronberk.ca/post/resource-links/</link>
      <pubDate>Sun, 11 Mar 2018 14:35:47 -0700</pubDate>
      
      <guid>http://aaronberk.ca/post/resource-links/</guid>
      <description>

&lt;h1 id=&#34;links-to-helpful-resources&#34;&gt;Links to helpful resources&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;A &lt;a href=&#34;https://www.youtube.com/playlist?list=PL5EvFKC69QIyRLFuxWRnH6hIw6e1-bBXB&#34; target=&#34;_blank&#34;&gt;42 video YouTube series&lt;/a&gt; by &amp;ldquo;the guy who wrote the Matlab function \&amp;ldquo;.&lt;/li&gt;
&lt;li&gt;A &lt;a href=&#34;https://www.youtube.com/watch?v=GF3iSJkgPbA&#34; target=&#34;_blank&#34;&gt;YouTube series&lt;/a&gt; on Conditional
Random Fields by Hugo Larochelle.&lt;/li&gt;
&lt;li&gt;One of myriad &lt;a href=&#34;https://towardsdatascience.com/ten-machine-learning-algorithms-you-should-know-to-become-a-data-scientist-8dc93d8ca52e&#34; target=&#34;_blank&#34;&gt;Medium lists&lt;/a&gt; of ML resources.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://unsupervisedmethods.com/over-150-of-the-best-machine-learning-nlp-and-python-tutorials-ive-found-ffce2939bd78&#34; target=&#34;_blank&#34;&gt;One more&lt;/a&gt; with a link to â‰¥ 150 tutorials&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.deeplearningbook.org/&#34; target=&#34;_blank&#34;&gt;DL book&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://deeplearning.net/reading-list/&#34; target=&#34;_blank&#34;&gt;DL.net reading list&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;blog-likes-that-i-think-are-good&#34;&gt;Blog-likes that I think are good&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://terrytao.wordpress.com/&#34; target=&#34;_blank&#34;&gt;Terry Tao&amp;rsquo;s blog&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.scottaaronson.com/blog/&#34; target=&#34;_blank&#34;&gt;Shtetl-Optimized&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Timothy &lt;a href=&#34;https://gowers.wordpress.com/&#34; target=&#34;_blank&#34;&gt;Gowers&amp;rsquo;s Weblog&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://varianceexplained.org/posts/&#34; target=&#34;_blank&#34;&gt;Variance Explained&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://opinionator.blogs.nytimes.com/author/steven-strogatz/&#34; target=&#34;_blank&#34;&gt;Steven Strogatz&lt;/a&gt; in the New York Times.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://undocumentedmatlab.com/&#34; target=&#34;_blank&#34;&gt;Undocumented Matlab&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://sbfnk.github.io/mfiidd/index.html&#34; target=&#34;_blank&#34;&gt;Model fitting and inference for infectious disease dynamics&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://image-processing-is-fun.blogspot.ca/&#34; target=&#34;_blank&#34;&gt;Image processing is fun!&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://twiecki.github.io/&#34; target=&#34;_blank&#34;&gt;Thomas Wiecki&amp;rsquo;s blog&lt;/a&gt; on Bayesian modelling and Python&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;other&#34;&gt;Other&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/pdf/1606.05908.pdf&#34; target=&#34;_blank&#34;&gt;Tutorial on Variational Autoencoders&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/pdf/1206.5538.pdf&#34; target=&#34;_blank&#34;&gt;Review on Representation Learning&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Matrix Completion Whirlwind</title>
      <link>http://aaronberk.ca/post/matrix-completion-whirlwind/</link>
      <pubDate>Thu, 14 Sep 2017 11:47:47 -0700</pubDate>
      
      <guid>http://aaronberk.ca/post/matrix-completion-whirlwind/</guid>
      <description>

&lt;h2 id=&#34;summary&#34;&gt;Summary&lt;/h2&gt;

&lt;p&gt;I recently wrote some basic Python functions for a matrix completion tutorial, covering elementary theory and a couple popular convex optimization methods for matrix completion.&lt;/p&gt;

&lt;p&gt;The &lt;a href=&#34;https://github.com/asberk/matrix-completion-whirlwind&#34; target=&#34;_blank&#34;&gt;repository is available&lt;/a&gt; on GitHub, including the Jupyter notebook, which can be &lt;a href=&#34;https://github.com/asberk/matrix-completion-whirlwind/blob/master/matrix_completion_master.ipynb&#34; target=&#34;_blank&#34;&gt;viewed on GitHub&lt;/a&gt;, as a &lt;a href=&#34;https://gist.github.com/asberk/8c8fd1e7f384df0183b8f01423c07a55&#34; target=&#34;_blank&#34;&gt;gist&lt;/a&gt;, or below.&lt;/p&gt;

&lt;h2 id=&#34;matrix-completion-whirlwind-gist&#34;&gt;Matrix completion whirlwind gist&lt;/h2&gt;

&lt;script type=&#34;text/javascript&#34; src=&#34;http://gist.github.com/8c8fd1e7f384df0183b8f01423c07a55.js&#34;&gt;&lt;/script&gt;

</description>
    </item>
    
    <item>
      <title>Neural Networks in Keras</title>
      <link>http://aaronberk.ca/project/neural-networks-keras/</link>
      <pubDate>Tue, 12 Sep 2017 21:03:04 -0700</pubDate>
      
      <guid>http://aaronberk.ca/project/neural-networks-keras/</guid>
      <description>

&lt;h2 id=&#34;description&#34;&gt;Description&lt;/h2&gt;

&lt;p&gt;This project is a five notebook tutorial available on GitHub, covering a brisk introduction to neural networks in &lt;code&gt;keras&lt;/code&gt; using &lt;code&gt;tensorflow&lt;/code&gt;. Note that various material has been borrowed, modified or shortened from the tensorflow and keras blogs. The repository is available on GitHub as &lt;a href=&#34;https://github.com/bcdataca/workshop-content/tree/master/1-first-week/mini-projects/3-neural-networks&#34; target=&#34;_blank&#34;&gt;Neural networks in &lt;code&gt;keras&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Matrix Completion</title>
      <link>http://aaronberk.ca/project/matrix-completion/</link>
      <pubDate>Tue, 12 Sep 2017 20:59:02 -0700</pubDate>
      
      <guid>http://aaronberk.ca/project/matrix-completion/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Reflection: 2017 BC Data Science Workshop</title>
      <link>http://aaronberk.ca/post/bcdata-workshop-2017/</link>
      <pubDate>Tue, 12 Sep 2017 19:47:28 -0700</pubDate>
      
      <guid>http://aaronberk.ca/post/bcdata-workshop-2017/</guid>
      <description>

&lt;h1 id=&#34;summary&#34;&gt;Summary&lt;/h1&gt;

&lt;p&gt;This is a brief summary and some incomplete reflections from my time as the workshop TA for the 2017 BC Data Science Workshop.&lt;/p&gt;

&lt;h2 id=&#34;about&#34;&gt;About&lt;/h2&gt;

&lt;p&gt;The &lt;a href=&#34;http://workshop.bcdata.ca/2017&#34; target=&#34;_blank&#34;&gt;BC Data Workshop&lt;/a&gt; was hosted August 9 &amp;ndash; 25 in downtown Vancouver at UBC Robson Square, co-organized by myself, Brian Wetton and Lee Rippon from the IAM, with support from PIMS and SFU Mathematics.&lt;/p&gt;

&lt;p&gt;The workshop featured a wide array of material from experts across the west coast, structured into three sections: a 3-day pre-workshop intensive; a week of introductory material; and a week-long data science project led by industry mentors.&lt;/p&gt;

&lt;h2 id=&#34;pre-workshop&#34;&gt;Pre-workshop&lt;/h2&gt;

&lt;p&gt;The pre-workshop was hosted by &lt;a href=&#34;http://www.math.ubc.ca/~pwalls/&#34; target=&#34;_blank&#34;&gt;Patrick Walls&lt;/a&gt; and &lt;a href=&#34;https://www.math.ubc.ca/~wetton/&#34; target=&#34;_blank&#34;&gt;Brian Wetton&lt;/a&gt;. It covered software carpentry material like GitHub, introductory Python and bash, and Jupyter notebooks. It also covered elements of scientific computing and machine learning like gradient descent, principal component analysis, fast Fourier transforms, convex optimization and linear regression.&lt;/p&gt;

&lt;h2 id=&#34;first-week&#34;&gt;First week&lt;/h2&gt;

&lt;p&gt;The mornings of the first week were comprised of introductory lectures by Isabell Konrad (UC Berkeley), Yinshan Zhao (BC Health) and Michael Reid (Amazon). Topics covered elements of machine learning and data science; hypothesis testing and experimental design; and modern software tools (SQL, Hadoop, Fink, Kafka, ElasticSearch, &lt;em&gt;etc.&lt;/em&gt;). In the afternoons, participants completed mini-projects whose focus was related either to the morning material, or to tools that would be integral to a project in the second week. The mini-projects covered regression, neural networks, matrix completion, data wrangling and exploration, and distributed and parallel computing with Apache Spark and tensorflow on GPU.&lt;/p&gt;

&lt;h2 id=&#34;second-week&#34;&gt;Second week&lt;/h2&gt;

&lt;p&gt;The mornings of the second week were comprised of &amp;ldquo;advanced topics&amp;rdquo; &amp;mdash; featuring professors from UBC or SFU, speaking on elements of their research which rely on or develop tools from data science. The rest of the time was devoted to group projects. Teams of 5 &amp;ndash; 7 worked on projects brought by industry mentors whose solutions would feature elements of data science. This included two kinds of image processing; nonlinear function approximation for video compression bitrate analysis; deep neural networks for genetics research; and analytics from vehicle time series messages.&lt;/p&gt;

&lt;h1 id=&#34;opportunities-and-challenges&#34;&gt;Opportunities and challenges&lt;/h1&gt;

&lt;h2 id=&#34;my-role-as-ta&#34;&gt;My role as TA&lt;/h2&gt;

&lt;p&gt;It was most rewarding to learn how to think in different modes with
teams of diverse individuals working on very diverse projects. One
evening, I got to help create an interpretable way to balance highly
imbalanced data; the next morning I had to help design a way to train
a deep model using images on a &lt;a href=&#34;https://github.com/bcdataca/bcsa-bcdata&#34; target=&#34;_blank&#34;&gt;remote
server&lt;/a&gt;. After that, I
contributed to a brainstorming session on how to &lt;a href=&#34;https://gist.github.com/asberk/1340166f2aa1b93607dae8645f4f9fb7&#34; target=&#34;_blank&#34;&gt;best cluster
data&lt;/a&gt;
that was too big for memory. In general, I got to contribute ideas for
project strategies, available software tools, and design/algorithm
troubleshooting.&lt;/p&gt;

&lt;h2 id=&#34;designing-mini-projects&#34;&gt;Designing mini-projects&lt;/h2&gt;

&lt;p&gt;An unintended consequence of the workshop saw me designing three of the five
mini-projects in the first week.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/bcdataca/workshop-content17/tree/master/1-first-week/mini-projects/2-matrix-completion&#34; target=&#34;_blank&#34;&gt;Matrix completion&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/bcdataca/workshop-content17/tree/master/1-first-week/mini-projects/3-neural-networks&#34; target=&#34;_blank&#34;&gt;Neural networks in keras&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/bcdataca/workshop-content17/tree/master/1-first-week/mini-projects/5-spark-aws&#34; target=&#34;_blank&#34;&gt;Parallel and distributed computing with &lt;code&gt;pyspark&lt;/code&gt; and &lt;code&gt;tensorflow-gpu&lt;/code&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Designing these consumed a lot of effort and time - too much given the other
organizational duties. Consequently, there are places where the work remains
unpolished. Nevertheless, designing these was a great opportunity to explore how
to communicate new concepts in an immersive, interactive way.&lt;/p&gt;

&lt;h2 id=&#34;project-duration&#34;&gt;Project duration&lt;/h2&gt;

&lt;p&gt;We may have imposed too great a constraint on the duration for which the teams
were able to work on their &lt;a href=&#34;http://workshop.bcdata.ca/2017/#projects&#34; target=&#34;_blank&#34;&gt;industry
projects&lt;/a&gt;. Effectively, they received
their projects Monday afternoon; had advanced lectures through the week; and had
to present on Friday afternoon. It&amp;rsquo;s clear that longer duration would have
indeed allowed significantly greater progress on the teams&amp;rsquo; projects. That being
said, each of the teams made an impressive amount of progress that will be
discussed below.&lt;/p&gt;

&lt;h1 id=&#34;about-the-projects&#34;&gt;About the projects&lt;/h1&gt;

&lt;h2 id=&#34;data-driven-modelling-of-video-compression&#34;&gt;Data-driven modelling of video compression&lt;/h2&gt;

&lt;p&gt;This project had aggregate camera data and sought to use this data to determine
a function that could accurately predict the bitrate for given camera
settings. The group tried several convex optimization approaches, and settled on
a particular flavour of random forest, boasting accuracy well above what is
considered &amp;ldquo;industry standard&amp;rdquo;.&lt;/p&gt;

&lt;h2 id=&#34;risk-based-platform-for-accdient-prevention&#34;&gt;Risk-based platform for accdient prevention&lt;/h2&gt;

&lt;p&gt;I helped to design a skeleton for this project, wherein the team would take raw
photo data from BC Safety Authority inspections and use it to predict compliant
and non-compliant objects using a combination approach of active learning and
transfer learning. The training would have be performed by downloading batches
of images from an AWS S3 bucket, since there were too many images to fit on the
VM disk we were using. It is likely that such a model will require more complex
structure than a standard image recognition ConvNet, such as topic modelling or
LDA.&lt;/p&gt;

&lt;p&gt;The team reduced the complexity of this task by classifying images of flowers
using a transfer learning approach. In this approach, these used bottlenecking
to generate feature vectors by running the images through the bottom several
layers of a VGG16 network. Then, they trained a binary classifier on this
markedly smaller feature space to discriminate between species of flowers. This
particular approach has immediate generalization potential to the more complex
problem of discerning compliant and non-compliant objects from inspection
photos.&lt;/p&gt;

&lt;h2 id=&#34;elucidating-enhancer-promoter-gene-expression-using-convnets&#34;&gt;Elucidating enhancer-promoter gene expression using ConvNets&lt;/h2&gt;

&lt;p&gt;This group developed a convolutional neural network whose first layer filters,
after [agnostic] training, were composed of significant and known gene promoter
regions. This convolutional neural network was designed to predict the efficacy
of gene expression for particular enhancer-promoter pairs. This team made
significant progress in the time they had, and made steps toward a
reverse-complement invariant machine learning model.&lt;/p&gt;

&lt;h2 id=&#34;data-insights-from-vehicle-time-series-messages&#34;&gt;Data insights from vehicle time series messages&lt;/h2&gt;

&lt;p&gt;The goal of this project was to learn novel insights from vehicle time series
messages, logged by in-car devices that record the car&amp;rsquo;s state, position,
etc. This team made significant progress toward the problem of discriminating
multiple drivers of the same vehicle. For this task, the team used Bayesian
methods and k-means.&lt;/p&gt;

&lt;h2 id=&#34;high-resolution-shoreline-data-for-flood-protection-and-environmental-conservation&#34;&gt;High-resolution shoreline data for flood protection and environmental conservation&lt;/h2&gt;

&lt;p&gt;This project sought to classify land type from photogrammetric drone image
data. The data was in the format of an unstructured sparse point cloud, listing
colour as well as latitude, longitude and elevation. The team took the approach
of looking at local variation in elevation, as well as point colour. The team
used an out-of-memory mini-batch k-means algorithm which clustered features
generated from a nearest neighbours tree. My own approach to this problem can be
&lt;a href=&#34;https://gist.github.com/asberk/1340166f2aa1b93607dae8645f4f9fb7&#34; target=&#34;_blank&#34;&gt;seen here&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Land type clustering from photogrammetric drone image data</title>
      <link>http://aaronberk.ca/project/bcdata-smartshores/</link>
      <pubDate>Tue, 12 Sep 2017 18:53:46 -0700</pubDate>
      
      <guid>http://aaronberk.ca/project/bcdata-smartshores/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Video Compression Analysis</title>
      <link>http://aaronberk.ca/project/bcdata-midvale-take1/</link>
      <pubDate>Tue, 12 Sep 2017 18:50:39 -0700</pubDate>
      
      <guid>http://aaronberk.ca/project/bcdata-midvale-take1/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Gradient Descent</title>
      <link>http://aaronberk.ca/project/gradient-descent/</link>
      <pubDate>Tue, 12 Sep 2017 18:46:08 -0700</pubDate>
      
      <guid>http://aaronberk.ca/project/gradient-descent/</guid>
      <description></description>
    </item>
    
    <item>
      <title></title>
      <link>http://aaronberk.ca/project/simplml/</link>
      <pubDate>Tue, 12 Sep 2017 18:32:06 -0700</pubDate>
      
      <guid>http://aaronberk.ca/project/simplml/</guid>
      <description></description>
    </item>
    
    <item>
      <title></title>
      <link>http://aaronberk.ca/project/wavelets-are-cool/</link>
      <pubDate>Sat, 12 Aug 2017 20:49:35 -0700</pubDate>
      
      <guid>http://aaronberk.ca/project/wavelets-are-cool/</guid>
      <description></description>
    </item>
    
    <item>
      <title>A Proof of CalderÃ³n&#39;s Formula</title>
      <link>http://aaronberk.ca/project/proof-calderon/</link>
      <pubDate>Mon, 24 Apr 2017 00:00:00 +0000</pubDate>
      
      <guid>http://aaronberk.ca/project/proof-calderon/</guid>
      <description></description>
    </item>
    
    <item>
      <title>MSc project submission</title>
      <link>http://aaronberk.ca/project/msc-proj/</link>
      <pubDate>Mon, 24 Apr 2017 00:00:00 +0000</pubDate>
      
      <guid>http://aaronberk.ca/project/msc-proj/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Parameter Stability in CS</title>
      <link>http://aaronberk.ca/project/iam-retreat-2017/</link>
      <pubDate>Mon, 24 Apr 2017 00:00:00 +0000</pubDate>
      
      <guid>http://aaronberk.ca/project/iam-retreat-2017/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Example Talk</title>
      <link>http://aaronberk.ca/talk/example-talk/</link>
      <pubDate>Sun, 01 Jan 2017 00:00:00 +0000</pubDate>
      
      <guid>http://aaronberk.ca/talk/example-talk/</guid>
      <description>&lt;p&gt;Embed your slides or video here using &lt;a href=&#34;https://gcushen.github.io/hugo-academic-demo/post/writing-markdown-latex/&#34; target=&#34;_blank&#34;&gt;shortcodes&lt;/a&gt;. Further details can easily be added using &lt;em&gt;Markdown&lt;/em&gt; and $\rm \LaTeX$ math code.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Enrichment map profiling of the cancer invasion front suggests regulation of colorectal cancer progression by the bone morphogenetic protein antagonist, gremlin-1</title>
      <link>http://aaronberk.ca/publication/grem-1/</link>
      <pubDate>Mon, 02 Sep 2013 00:00:00 +0000</pubDate>
      
      <guid>http://aaronberk.ca/publication/grem-1/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
